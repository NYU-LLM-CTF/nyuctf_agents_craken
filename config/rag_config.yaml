database:
  storage: 'milvus'
  config:
    # IVF_FLAT/HNSW
    index_type: "IVF_FLAT"  
    # L2/COSINE
    metric_type: "L2"        

agent:
  model:
    type: "openai"
    name: "gpt-4o-mini-2024-07-18"
    temperature: 1

retrieval:
  reranker:
    type: "RankLLMRerank"
    model: "gpt-4o-mini-2024-07-18"
    top_n: 3    
    threshold: 0.3   
  compressor:
    type: "LLMChainExtractor"
    retriever: "ContextualCompressionRetriever"
    parameters:
      max_length: 256 
  retriever:
    # similarity_search/MMR
    type: "similarity_search"
    # similarity/hybrid/bm25'
    search_type: "similarity"
    params:
      k: 20
      ef: 30
  template: 
    qa: |
      You are an assistant for question-answering tasks.
      Use the following pieces of retrieved context to answer the question.
      If you don't know the answer, just say that you don't know.
      Use three sentences maximum and keep the answer concise.
      Question: {question}
      Context: {context}
      Answer:
    multi_query: |
      You are an AI language model assistant. 
      Your task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. 
      By generating multiple perspectives on the user question, 
      your goal is to help the user overcome some of the limitations of the distance-based similarity search. 
      Provide these alternative questions separated by newlines. 
      Original question: {question}
    decompose_query: |
      You are a helpful assistant that generates multiple sub-questions related to an input question.
      The goal is to break down the input into a set of sub-problems or sub-questions that can be answered individually.
      Generate multiple search queries related to: {question}
      Output (3 queries):
    answer_decompose_query: |
      Here is the question you need to answer:
      \n --- \n {question} \n --- \n
      Here is any available background question + answer pairs:
      \n --- \n {q_a_pairs} \n --- \n
      Here is additional context relevant to the question: 
      \n --- \n {context} \n --- \n
      Use the above context and any background question + answer pairs to answer the question: \n {question}
    step_back: |
      You are an expert of world knowledge. I am going to ask you a question. Your response should synthesize both the original and paraphrased contexts.
      Context from the original question:
      {normal_context}
      Context from the paraphrased question:
      {step_back_context}
      Original Question: {question}
      Synthesized Answer:
  collection: "HFCTF"

features:
  search_params: False
  rerank: True
  compressor: False
  multi_query: False
  rag_fusion: False
  decomposition: False
  step_back: False
